---
title: |
  Depression Trajectories in the ABCD Study
short-title: Depression Trajectories
code-repo: "Access the code, data, and analysis at <https://github.com/OpenDevSci/SUNLab>"
number-sections: true
number-depth: 3
correspondence-prefix: "Correspondence concerning this article should be addressed to"
author:
- name: Jane D. Doe
  email: janedoe@fiu.edu
  affiliations:
    name: Florida International University
    department: Center for Children & Families
    city: Miami
    region: FL
    country: United States
- name: John D. Doe
  email: johndoe@fiu.edu
  affiliations:
    name: Florida International University
    department: Center for Children & Families
    city: Miami
    region: FL
    country: United States

abstract: |
  xxxxxxxxx Input abstract here.

index-terms: 
  - depression
  - substance use
  - ABCD Study

format:
  docx: default
  ieee-typst: default
  html:
    page-layout: article
    toc: true
    toc-depth: 1
    toc-expand: 2
    toc-title: Table of Contents
    code-tools:
      source: true
      toggle: false
      caption: none
    grid:
      sidebar-width: 350px
      margin-width: 20px
bibliography: references.bib

execute:
  freeze: auto  # re-render only when source changes
  cache: true
---

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE
#| cache: FALSE

# Load the necessary libraries

library(tidySEM)
library(tidyverse)
library(ggplot2)
library(easystats)
library(broom)
library(report)
library(gridExtra)
library(lorem)

# Set the data paths
data_path <- "/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds"

# Read the data
df_temp1 <- readRDS(data_path)

# Creating df_long

## Subset the nonimaging data to include chosen variables
selected_vars <- c("src_subject_id", "eventname", "cbcl_scr_dsm5_depress_t")
df_long <- df_temp1[, selected_vars]

## Define event names to be retained in the analysis and convert variables to appropriate data types
eventnames_to_include <- c(
    "baseline_year_1_arm_1",
    "1_year_follow_up_y_arm_1",
    "2_year_follow_up_y_arm_1",
    "3_year_follow_up_y_arm_1",
    "4_year_follow_up_y_arm_1"
)

df_long <- df_long %>%
    filter(eventname %in% eventnames_to_include) %>%
    mutate(
        src_subject_id = as.factor(src_subject_id),
        eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),
        cbcl_scr_dsm5_depress_t = as.numeric(cbcl_scr_dsm5_depress_t),
    ) %>%
    ## Exclude cases from unused assessment waves
    filter(!is.na(eventname))

df_long <- na.omit(df_long)

# Creating df_wide
df_wide <- pivot_wider(
    data = df_long,
    names_from = eventname,
    values_from = cbcl_scr_dsm5_depress_t,
    id_cols = src_subject_id
)

df_wide <- df_wide %>%
    rename(
        depress.0 = baseline_year_1_arm_1,
        depress.1 = `1_year_follow_up_y_arm_1`,
        depress.2 = `2_year_follow_up_y_arm_1`,
        depress.3 = `3_year_follow_up_y_arm_1`,
        depress.4 = `4_year_follow_up_y_arm_1`
    )

## Subset the nonimaging data to include desired variables
selected_vars_wide <- c("depress.0", "depress.1", "depress.2", "depress.3", "depress.4")
df_wide <- df_wide[, selected_vars_wide]

```

# Introduction

[The Adolescent Brain Cognitive Development (ABCD) StudyÂ®](https://abcdstudy.org/ "Visit the ABCD Study website"){#abcdwebsite} is the largest longitudinal investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental factors impacting neurodevelopment and their roles in behavioral and health outcomes across ten years of adolescence @volkow2018.

"Studies investigating trajectories of depressive symptoms @gao2021, @kaup2016, @lin2023, @zhang2022. Musliner et al. (2016) @musliner2016 conducted a systematic review on the heterogeneity in long-term patterns of depressive symptoms and found that most of these studies identified three or four different symptom trajectories and sampled the general population."

"A valuable tool for investigating heterogeneity in symptom patterns is Latent Growth Curve Modelling (GCM), a statistical method that analyses inter-individual variability in intra-individual patterns over time @curran2010. One specific type of GCM is Latent Class Growth Analysis (LCGA), which considers unobserved heterogeneity (different groups) over time within a larger population @jung2008, @nguena2020, @ram2009. In other words, LCGA can examine the growth and shape of the course of depressive symptoms over time and assess how individuals in the population group together based on their symptom patterns."

"The aim of the present study is to investigate the course of depressive symptoms over a period of xx years .... and to .... . To achieve this goal, LGCM will be performed on data from the xxxx ABCD cohort (add citation). The ABCD study was initiated in xxxxx. Based on previous literature @musliner2016, we hypothesize that three or four trajectories of depression can be identified. Given that xxxxx, we additionally hypothesize that individuals following more xxxx trajectories will be more/less likely to experience xxxx and exhibit reduced levels of xxxxx"

# Methods

## Design and participants

Participants were enrolled in the ongoing, longitudinal ABCD Study. The ABCD Study recruited a cohort of n=11,880 participants born between 2006-2008 and aged approximately 9-10 years at baseline, each with a parent/guardian. The study sample was recruited from households in defined catchment areas for each of the 21 (originally 22) study sites across the United States. The present study examines data from the fifth public release of ABCD Study data (version 5.1, released xxxx 202x https://data-archive.nimh.nih.gov/abcd). Institutional review boards at participating universities approved all study procedures. Participants provided written assent, and their legal guardians written consent, for participation. Information regarding funding agencies, recruitment sites, investigators, and project organizations can be obtained at https://abcdstudy.org. The ABCD Study design is described in more detail in @garavan2018 and @dick2021.

\[baseline (T0) measurement; follow-up measurements (T1) (T2)(T3)(T4)\]

## Measures

### Depression

Depression was assessed using the Child Behavior Checklist (CBCL), a widely used parent-report questionnaire designed to identify problem behavior in children and adolescents aged 6 to 18 years @achenbach2000. The CBCL is comprised of various scales that measure different aspects of emotional and behavioral problems. Specifically, the Depressive Problems scale, which is part of the broader Internalizing Problems domain, was utilized to measure symptoms of depression. This scale includes items that assess a range of depressive symptoms such as persistent sadness, lack of interest in activities, and excessive guilt or feelings of worthlessness. Respondents (parents or primary caregivers) were asked to rate how true each item was for their child over the past six months on a 3-point Likert scale ranging from 0 (not true) to 2 (very true or often true). The scores from the relevant items were summed to create a composite score for depressive symptoms, with higher scores indicating greater severity of depressive symptoms @goldstone2020. CBCL symptom scores below the 93rd percentile (T = 65) are considered normal, scores between the 93-97th percentile (T = 65--69) are borderline clinical, and any score above the 97th percentile (T = 69) are in the clinical range @maruish2004. Scores in the borderline range are high enough to be of concern @maruish2004. The CBCL has demonstrated strong psychometric properties @achenbach2000 and its use in assessing depressive symptoms is supported by numerous studies, including those using ABCD Study data @barch2018, @goldstone2020, @gorham2019, @hoffman2019

### Add other measures

### Potential confounders

To account for the potentially confounding effects of attentional, cognitive, or emotional difficulties that are often comorbid with depression, all analyses included CBCL DSM-oriented xxx problems and xxx problems subscale scores as covariates. We also covaried for sex, age, race/ethnicity, and parental education.

## Analytic Plan

### Descriptive Statistics

Participants with CBCL depression scores at one or more time point(s) were included in the trajectory analysis. Groups with and without any missing scores on the depression outcome at each time point were compared.

### Trajectory Models

Variability in depressive symptom trajectories was examined using latent class growth analysis (LCGA; @jung2008, @andruff2009, @berlin2014, @wardenaar2020). LCGA is a person-centered method that identifies latent classes of individuals sharing similar developmental patterns, thereby facilitating an examination of individual patterns of stability and change across time @jung2008, @nguena2020, @ram2009. Prior research (@musliner2016) suggests three to six distinct depressive trajectory subgroups, prompting the estimation of models ranging from one to seven classes. To capture changes in depressive symptomatology over time, both linear and quadratic terms were considered. Differentiation among trajectories regarding intercept, slope, and step was evaluated using Wald tests. An examination of the data revealed a skewed distribution, notably inflated at the scale's lower end. Initial analyses resulted in LCGA model convergence issues due to this skewness. As such, a Box-Cox transformation was implemented (See Fig. xx) to improve the ability to examine patterns of heterogeneity in more detail. To evaluate the effect of covariates, we adhered to a commonly applied, three-step approach which accounts for classification errors of the model @vermunt2010. This method estimates an auxiliary model based on latent classification, assigning group-specific BCH weights to cases (@bolck2004). 

Next, an omnibus likelihood ratio test was examined to test for significant differences in trajectory patterns. For all omnibus likelihood ratio tests the p-values were corrected for multiple comparisons using the false discovery rate. If the omnibus test was still significant after correction, post hoc test results were obtained and likewise subjected to correction for multiple comparisons using the false discovery rate.ll analyses were performed using the programming language R (version 4.2.2, package for trajectory analysis: tidySEM, @van2023) (with significance level set at p \< .05 (two-tailed)). All R code is made publicly available on GitHub at https://github.com/OpenDevSci/SUNLab.

Identification of the best fitting model was based on a combination of interpretability, parsimony, and theoretical justification @nagin2010, @nguena2020, @ram2009. Key metrics for assessing model fit include Information Criteria (IC) such as the Bayesian Information Criteria (BIC), the sample-size-adjusted BIC (saBIC), and the Akaike Information Criteria (AIC), with a preference for models that register the lowest IC values @nylund2007, @van2020, @van2023. In cases of ambiguous and contradictory ICs, evaluation of a scree plot's inflection point may assist in determining the point beyond which additional classes offer negligible improvement to IC reduction @nylund2018. Model performance was appraised through a range of indicators including entropy, posterior classification probability (the likelihood of an individual's correct class assignment), and class size. Solutions yielding distinct classes were prioritized to facilitate clear interpretation. High entropy values signify well-differentiated classes @van2023, @weller2020; thus, configurations with entropy below .90 were excluded. Moreover, when an individualâ€™s posterior classification probability is distinctly high for one class compared to others, it denotes effective class differentiation by the model @andruff2009. Criteria set for acceptable solutions included an average posterior classification probability exceeding .90 @weller2020. Additionally, drawing on prior studies, a minimum class size of 50 individuals or 5% of the overall sample was deemed necessary to ensure representativeness @muthen2000, @weller2020, leading to the exclusion of classes not meeting this threshold.

Data processing and analysis were executed using the tidySEM package in R @van2023, employing [full information maximum likelihood estimation to accommodate standard errors and provide a chi-square statistic robust to non-normality(?)]. Complex sampling and recruitment procedures for the ABCD Study were accounted for using cluster correction (i.e., for sibling pairs) and stratification sampling (i.e. study site) procedures.

## Depression symptoms associations with the GDT & substance use

To get more insights in the trajectories and associated outcomes (e.g., GDT, substance use), we assessed xxxxx between the different classes. We used the same three-step approach with the omnibus likelihood test used for the covariates and the results were also corrected for multiple comparisons. All participants reported xxxx during xxxx.

## Add additional analyses section

# Results

### Descriptive Statistics

Descriptive statistics revealed that the study groups were equivalent on demographic variables, except for lower proportional representation of female and Hispanic children in the xxxx groups (see Table 1). This study included xxx participants (xxx \[xx.xx%\] women, xxx \[xx.xx\] men); mean (SD) XXX was xx.xx (x.xx). Table 1 provides other demographic characteristics, including race, family income, parental education attainment for each trajectory pattern. Moreover, there were no significant differences between participants missing any depression measurements and participants with complete depression scores at each time point. 

### Trajectory Models

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

# Data preprocessing
# We first examined the descriptive statistics for the sum score scales:
# df_wide Descriptives

desc <- descriptives(df_wide)
desc <- desc[, c(
    "name", "mean", "median", "sd", "min", "max",
    "skew_2se", "kurt_2se"
)]
knitr::kable(desc, caption = "Item descriptives")

```

We can examine these distributions visually as well:

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

# df_long Plots
ggplot(df_long, aes(x = cbcl_scr_dsm5_depress_t)) +
    geom_density() +
    facet_wrap(~eventname) +
    theme_bw()

```

As this type of skew can result in convergence problems in LCGA, we compared several transformations to reduce skew: The square and cube root, log, inverse, and Box-Cox transformations.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE

df_scores <- df_long
# Store original range of cbcl_scr_dsm5_depress_t
rng_depress <- range(df_scores$cbcl_scr_dsm5_depress_t, na.rm = TRUE)
# Log-transform
df_scores$log <- scales::rescale(log(df_scores$cbcl_scr_dsm5_depress_t), to = c(
    0,
    1
))
# Square root transform
df_scores$sqrt <- scales::rescale(sqrt(df_scores$cbcl_scr_dsm5_depress_t), to = c(
    0,
    1
))
# Cube root transform
df_scores$qrt <- scales::rescale(df_scores$cbcl_scr_dsm5_depress_t^0.33, to = c(
    0,
    1
))
# Reciprocal transform
df_scores$reciprocal <- scales::rescale(1 / df_scores$cbcl_scr_dsm5_depress_t, to = c(
    0,
    1
))
# Define function for Box-Cox transformation
bc <- function(x, lambda) {
    (((x^lambda) - 1) / lambda)
}
# Inverse Box-Cox transformation
invbc <- function(x, lambda) {
    ((x * lambda) + 1)^(1 / lambda)
}
# Box-Cox transform
b <- MASS::boxcox(lm(df_scores$cbcl_scr_dsm5_depress_t ~ 1), plotit = FALSE)
lambda <- b$x[which.max(b$y)]
df_scores$boxcox <- bc(df_scores$cbcl_scr_dsm5_depress_t, lambda)
# Store range of Box-Cox transformed data
rng_bc <- range(df_scores$boxcox)
df_scores$boxcox <- scales::rescale(df_scores$boxcox, to = c(
    0,
    1
))
# Rescale cbcl_scr_dsm5_depress_t
df_scores$cbcl_scr_dsm5_depress_t <- scales::rescale(df_scores$cbcl_scr_dsm5_depress_t, to = c(0, 1))

```

We can plot these transformations:

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

# Make plot data
df_plot <- do.call(rbind, lapply(c(
    "cbcl_scr_dsm5_depress_t", "log", "sqrt", "qrt",
    "boxcox"
), function(n) {
    data.frame(df_scores[c("eventname", "src_subject_id")],
        Value = df_scores[[n]],
        Transformation = n
    )
}))
# Plot
ggplot(df_plot, aes(x = Value, colour = Transformation)) +
    geom_density() +
    facet_wrap(~eventname) +
    scale_y_sqrt() +
    xlab("Depression (rescaled to 0-1)") +
    theme_bw()
```

The Box-Cox transformation (maybe/slightly?) reduced skew the most. Consequently, we proceeded with the Box-Cox transformed scores for analysis.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE

dat <- df_scores[, c("src_subject_id", "eventname", "boxcox")]
dat <- reshape(dat,
    direction = "wide", v.names = "boxcox", timevar = "eventname",
    idvar = "src_subject_id"
)

dat <- na.omit(dat)

names(dat) <- gsub("boxcox.", "depress", names(dat))
```

#### Model Selection

A complete table of model characteristics and fit statistics of the linear and quadratic models are shown in Supplementary Table S5. A selection of characteristics and fit statistics is presented in Table 2 for the linear models. All quadratic models, except the one-class quadratic model, encountered convergence problems and failed to find a final solution. This suggests that the quadratic models are too complex for our dataset @van2023. While it is feasible to explore alternative non-linear patterns, the persisting issue lies in the apparent complexity associated with models incorporating many parameters. For the linear models, a reduction in BIC, saBIC and AIC was observed with increasing class number. The reduction in ICs flattened after three classes. In addition, the LoMendell-Rubin (LMR) likelihood ratio test was significant with every additional class and entropy was above.90 for all models. Posterior group probability was acceptable (above.90) up to the four-class model. Therefore, the models with five or more classes were not accepted. For all models with one to four classes, the class size was larger than 5% and consisted of at least 50 individuals. Altogether, most quadratic models did not converge, and both the three- and four-class model performed well and had acceptable classification performance. Therefore, we selected the linear three-class model as the final model.

#### Depression trajectories

The three classes identified were a xx class with xx participants (xx%), an xx class with xx participants (xx%), and a xx class with xx participants (xx%) (Fig. x). The xxx group showed low levels of depressive symptoms xxxx. The xxx and xxx group showed a significant increase in depressive symptoms. The xxxx group started xxxx, and showed a significant xxxxx. Results of the Wald tests (Supplementary Table S8) showed that the xxxxx scores for depressive symptoms (intercepts) and the increase from xxxx differed significantly between all classes (p \< .01). Furthermore, the trajectories differed significantly in slope (p \< .01). (See Supplement for pairwise comparisons with Bonferroni correction).

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: FALSE

set.seed(27796)
dat[["src_subject_id"]] <- NULL
res_step <- mx_growth_mixture(
    model = "
  i =~ 1*depressbaseline_year_1_arm_1 + 1*depress1_year_follow_up_y_arm_1 + 1*depress2_year_follow_up_y_arm_1 +1*depress3_year_follow_up_y_arm_1 +1*depress4_year_follow_up_y_arm_1
  step =~ 0*depressbaseline_year_1_arm_1 + 1*depress1_year_follow_up_y_arm_1 + 1*depress2_year_follow_up_y_arm_1 +1*depress3_year_follow_up_y_arm_1 +1*depress4_year_follow_up_y_arm_1
  s =~ 0*depressbaseline_year_1_arm_1 + 0*depress1_year_follow_up_y_arm_1 + 1*depress2_year_follow_up_y_arm_1 +2*depress3_year_follow_up_y_arm_1 +3*depress4_year_follow_up_y_arm_1
  depressbaseline_year_1_arm_1 ~~ vdepressbaseline_year_1_arm_1*depressbaseline_year_1_arm_1
  depress1_year_follow_up_y_arm_1 ~~ vdepress1_year_follow_up_y_arm_1*depress1_year_follow_up_y_arm_1
  depress2_year_follow_up_y_arm_1 ~~ vdepress2_year_follow_up_y_arm_1*depress2_year_follow_up_y_arm_1
  depress3_year_follow_up_y_arm_1 ~~ vdepress3_year_follow_up_y_arm_1*depress3_year_follow_up_y_arm_1
  depress4_year_follow_up_y_arm_1 ~~ vdepress4_year_follow_up_y_arm_1*depress4_year_follow_up_y_arm_1
  i ~~ 0*i
  step ~~ 0*step
  s ~~ 0*s
  i ~~ 0*s
  i ~~ 0*step
  s ~~ 0*step",
    classes = 1:3, data = dat
)
# Additional iterations because of convergence problems for
# model 1:
res_step[[1]] <- mxTryHardWideSearch(res_step[[1]], extraTries = 50)
```

Note that the first model showed convergence problems, throwing the error: The model does not satisfy the first-order optimality conditions to the required accuracy, and no improved point for the merit function could be found during the final linesearch. To address this problem, we performed additional iterations to find a better solution, using OpenMx::mxTryHardWideSearch(). This also illustrates that tidySEM mixture models inherit from OpenMx's MxModel, and thus, different OpenMx functions can be used to act on models specified via tidySEM.

The fifth model also evidenced convergence problems, but this (as we will see) is because the solution is overfitted.

Class enumeration To determine the correct number of classes, we considered the following criteria:

We do not consider classes with, on average, fewer than 5 participants per parameter in a class due to potential local underidentification Lower values for information criteria (AIC, BIC, saBIC) indicate better fit Significant Lo-Mendell-Rubin LRT test indicates better fit for ð‘˜ vs ð‘˜âˆ’1 classes We do not consider solutions with entropy \< .90 because poor class separability compromises interpretability of the results We do not consider solutions with minimum posterior classification probability \< .90 because poor class separability compromises interpretability of the results

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

# Get fit table fit
tab_fit <- table_fit(res_step)
# Select columns
tab_fit[, c("Name", "Classes", "LL", "Parameters", "AIC", "BIC", "saBIC", "Entropy", "prob_min", "n_min")]

# , "warning", "lmr_p")]

```

According to the Table, increasing the number of classes keeps improving model fit according to all ICs.

The first two LMR tests are significant, indicating that a 2- and 3-class solution were a significant improvement over a 1- and 2-class solution, respectively. However, solutions with \>3 classes had entropy and minimum posterior classification probability below the pre-specified thresholds. Models with \>3 solutions also had fewer than five observations per parameter. This suggests that the preferred model should be selected from 1-3 classes.

Scree plot A scree plot indicates that the largest decrease in ICs occurs from 1-2 classes, and the inflection point for all ICs is at 3 classes. Moreover, the BIC increased after 3 classes. A three-class solution thus appears to be the most parsimonious solution with good fit.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

plot(tab_fit, statistics = c("AIC", "BIC", "saBIC"))
```

Based on the aforementioned criteria, we selected a 3-class model for further analyses. First, to prevent label switching, we re-order these classes by the value of the intercept i. Then, we report the estimated parameters.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

res_final <- mx_switch_labels(res_step[[3]],
    param = "M[1,7]",
    decreasing = FALSE
)
tab_res <- table_results(res_final, columns = NULL)
# Select rows and columns
tab_res <- tab_res[
    tab_res$Category %in% c("Means", "Variances"),
    c("Category", "lhs", "est", "se", "pval", "confint", "name")
]
tab_res
```

As evident from these results, Class 1 started at a relatively lower level of depressive symptoms, experienced a decrease after deployment, followed by increase over time. Class 2 started at a moderate level of depressive symptoms, experienced an increase after deployment, followed by significant increase over time from T2-T6. Class 3 started at a relatively higher level, experienced an increase after deployment, followed by stability.

Wald tests To test whether parameters are significantly different between classes, we can use Wald tests. Wald tests can be specified for all parameters in the model, using the hypothesis syntax from the bain package for informative hypothesis testing.

To identify the names of parameters in the model, we can use the name column of the results table above. Alternatively, to see all parameters in the model, run:

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

names(coef(res_final))
```

Next, specify equality constrained hypotheses. For example, a hypothesis that states that the mean intercept is equal across groups is specified as follows:

"class1.M\[1,7\] = class2.M\[1,7\] & class1.M\[1,7\] = class3.M\[1,7\]

It is also possible to consider comparisons between two classes at a time. When conducting many significance tests, consider correcting for multiple comparisons however.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

wald_tests <- wald_test(res_final, "
                   class1.M[1,6] = class2.M[1,6] &
                   class1.M[1,6] = class3.M[1,6] ;
                   class1.M[1,7] = class2.M[1,7] &
                   class1.M[1,7] = class3.M[1,7] ;
                   class1.M[1,8] = class2.M[1,8] &
                   class1.M[1,8] = class3.M[1,8]")

# Rename the hypothesis
wald_tests$Hypothesis <- c("Mean i", "Mean step", "Mean slope")
knitr::kable(wald_tests, digits = 2, caption = "Wald tests")

```

All Wald tests are significant, indicating that there are significant differences between the intercepts, step function, and slopes of the three classes.

Trajectory plot Finally, we can plot the growth trajectories. This can help interpret the results better, as well as the residual heterogeneity around class trajectories.

```{r}
#| echo: FALSE
#| messages: FALSE
#| warning: FALSE
#| output: TRUE

p <- plot_growth(res_step[[3]], rawdata = TRUE, alpha_range = c(
    0,
    0.05
))
# Add Y-axis breaks in original scale
brks <- seq(0, 1, length.out = 5)
labs <- round(invbc(
    scales::rescale(brks, from = c(0, 1), to = rng_bc),
    lambda
))
p <- p + scale_y_continuous(
    breaks = seq(0, 1, length.out = 5),
    labels = labs
) + ylab("Depression (rescaled from Box-Cox)")
p
```

Note that the observed individual trajectories show very high variability within classes.

#### Covariates

Assessment of covariates using the three-step approach revealed that the trajectories did not differ in any of the demogra phical variables, including sex (Î”LL(5) = 6.3 , p = .27, pcorr = .37), age (Î”LL(8) = 8.4 , p = .40, pcorr = .50), rank Journal of Affective Disorders 354 (2024) 702--711 707(Î”LL(11) = 13.5 , p = .26, pcorr = .37), educational level (Î”LL(9) = 7.1 , p = .63, pcorr = .66), function (Î”LL(8) = 8.1 , p = .43, pcorr = .51), year of deployment (Î”LL(5) = 3.6 , p = .61, pcorr = 66), or previous deployments (Î”LL(6) = 3.0 , p = .81, pcorr = .81). For early life traumas, the symptomatic-chronic group experienced more early life traumas compared to the other trajectories (p \< .01, pcorr \< .01) and both the resilient and late-onset-increasing group experienced significantly less early life traumas compared to the intermediate-stable group (Î”LL(2) = 21.6 , p \< .01, pcorr \< .01; Î”LL(2) = 8.1 , p \< .05, pcorr \< .05) (Supple- mentary Fig. S10). Significant disparities in the number of deployment stressors were observed, with the resilient group exhibiting lower counts of deploy- ment stressors compared to the intermediate-stable group (Î”LL(2) = 23.0 , p \< .01, pcorr \< .01), symptomic-chronic group (Î”LL(2) = 325.7 , p \< .01, pcorr \< .01), and late-onset-increasing group (Î”LL(2) = 9.5 , p \< .01, pcorr \< .05) (Supplementary Fig. S11). A detailed breakdown of percentages per stressor is provided in Supple- mentary Table S12

#### Depression and GDT

#### Depression and substance use

## Add additional analyses section

# Discussion

```{r}

lorem::ipsum(5, sentences = c(3))
# lorem::ipsum(2, avg_words_per_sentence = 4)

```

# Acknowledgements

Data used in the preparation of this article were obtained from the Adolescent Brain Cognitive DevelopmentSM (ABCD) Study (https://abcdstudy.org), held in the NIMH Data Archive (NDA). This is a multisite, longitudinal study designed to recruit more than 10,000 children age 9-10 and follow them over 10 years into early adulthood. The ABCD StudyÂ® is supported by the National Institutes of Health and additional federal partners under award numbers U01DA041048, U01DA050989, U01DA051016, U01DA041022, U01DA051018, U01DA051037, U01DA050987, U01DA041174, U01DA041106, U01DA041117, U01DA041028, U01DA041134, U01DA050988, U01DA051039, U01DA041156, U01DA041025, U01DA041120, U01DA051038, U01DA041148, U01DA041093, U01DA041089, U24DA041123, U24DA041147. A full list of supporters is available at https://abcdstudy.org/federal-partners.html. A listing of participating sites and a complete listing of the study investigators can be found at https://abcdstudy.org/consortium_members/. ABCD consortium investigators designed and implemented the study and/or provided data but did not necessarily participate in the analysis or writing of this report. This manuscript reflects the views of the authors and may not reflect the opinions or views of the NIH or ABCD consortium investigators.

The ABCD data repository grows and changes over time. The ABCD data used in this report came from DOI: 10.15154/z563-zd24. DOIs can be found at the following [link](https://nda.nih.gov/study.html?id=2313).

<br>

# References
